{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b73f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================== TF-IDF: Exercises ===================\n",
    "# Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or \n",
    "# in form of words.\n",
    "\n",
    "# In Social Media like Twitter and Instagram, many people express their views through comments about a particular \n",
    "# event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    "\n",
    "# For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular \n",
    "# comment belongs!\n",
    "\n",
    "# We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different \n",
    "# classification algorithms.\n",
    "\n",
    "# ===== About Data: Emotion Detection\n",
    "# Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "# This data consists of two columns. - Comment - Emotion\n",
    "\n",
    "# Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "# Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "# As there are only 3 classes, this problem comes under the Multi-Class Classification.\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv(\"Emotion_classify_Data.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dcdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of Emotion\n",
    "df['Emotion'].value_counts()\n",
    "\n",
    "# From the above, we can see that almost the Emotions(classes) occured equal number of times and balanced. There is no problem \n",
    "# of class imbalance and hence no need to apply any balancing techniques like undersampling, oversampling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6591dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num\n",
       "0  i seriously hate one subject to death but now ...    fear            1\n",
       "1                 im so full of life i feel appalled   anger            2\n",
       "2  i sit here to write i start to dig out my feel...    fear            1\n",
       "3  ive been really angry with r and i feel like a...     joy            0\n",
       "4  i feel suspicious if there is no one outside l...    fear            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "df['Emotion_num'] = df['Emotion'].map({\n",
    "    'joy': 0,\n",
    "    'fear': 1,\n",
    "    'anger': 2\n",
    "})\n",
    "\n",
    "#checking the results by printing top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecbfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Modelling without Pre-processing Text data ============\n",
    "\n",
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "#Note: Give Random state 2022 and also do the stratify sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Comment,\n",
    "    df.Emotion_num,\n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.Emotion_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e06eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (4749,)\n",
      "Shape of X_test:  (1188,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdb8b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.28      0.38       400\n",
      "           1       0.37      0.79      0.50       388\n",
      "           2       0.53      0.24      0.34       400\n",
      "\n",
      "    accuracy                           0.43      1188\n",
      "   macro avg       0.50      0.44      0.41      1188\n",
      "weighted avg       0.50      0.43      0.41      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Attempt 1 : ============\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "# Note:\n",
    "\n",
    "# using CountVectorizer with only trigrams.\n",
    "# use RandomForest as the classifier.\n",
    "# print the classification report.\n",
    "# ====================================\n",
    "\n",
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tri_grams', CountVectorizer(ngram_range = (3, 3))),\n",
    "    ('random_forest', (RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987b02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.87      0.83      0.85       388\n",
      "           2       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.86      1188\n",
      "   macro avg       0.86      0.86      0.86      1188\n",
      "weighted avg       0.86      0.86      0.86      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========== Attempt 2 : ===============\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "# Note:\n",
    "\n",
    "# using CountVectorizer with both unigram and bigrams.\n",
    "# use Multinomial Naive Bayes as the classifier.\n",
    "# print the classification report.\n",
    "# ========================================\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bigrams', CountVectorizer(ngram_range = (1, 2))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff54d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       400\n",
      "           1       0.95      0.89      0.92       388\n",
      "           2       0.93      0.87      0.90       400\n",
      "\n",
      "    accuracy                           0.91      1188\n",
      "   macro avg       0.91      0.91      0.91      1188\n",
      "weighted avg       0.91      0.91      0.91      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============== Attempt 3 : ===============\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "# Note:\n",
    "\n",
    "# using CountVectorizer with both unigram and bigrams.\n",
    "# use RandomForest as the classifier.\n",
    "# print the classification report.\n",
    "# ===========================================\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bi_grams', CountVectorizer(ngram_range = (1, 2))),                       #using the ngram_range parameter \n",
    "    ('random_forest', (RandomForestClassifier()))         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64649e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       400\n",
      "           1       0.92      0.90      0.91       388\n",
      "           2       0.93      0.86      0.89       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= Attempt 4 : ===================\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "# Note:\n",
    "\n",
    "# using TF-IDF vectorizer for pre-processing the text.\n",
    "# use RandomForest as the classifier.\n",
    "# print the classification report.\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb8b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Use text pre-processing to remove stop words, punctuations and apply lemmatization =============\n",
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f77d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "df['preprocessed_comment'] = df['Comment'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d6d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Build a model with pre processed text ============\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Use the preprocessed_Comment\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.preprocessed_comment, \n",
    "    df.Emotion_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.Emotion_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc3d7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       400\n",
      "           1       0.94      0.92      0.93       388\n",
      "           2       0.93      0.94      0.93       400\n",
      "\n",
      "    accuracy                           0.94      1188\n",
      "   macro avg       0.94      0.94      0.94      1188\n",
      "weighted avg       0.94      0.94      0.94      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the scores with our best model till now\n",
    "\n",
    "# Random Forest\n",
    "# ======= Attempt1 :\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "# Note:\n",
    "\n",
    "# using CountVectorizer with both unigrams and bigrams.\n",
    "# use RandomForest as the classifier.\n",
    "# print the classification report.\n",
    "# ===================================\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bi_grams', CountVectorizer(ngram_range = (1, 2))),                       #using the ngram_range parameter \n",
    "    ('random_forest', (RandomForestClassifier()))         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6896659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       400\n",
      "           1       0.93      0.91      0.92       388\n",
      "           2       0.94      0.91      0.92       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====== Attempt 2 :\n",
    "\n",
    "# using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "# Note:\n",
    "\n",
    "# using TF-IDF vectorizer for pre-processing the text.\n",
    "# use RandomForest as the classifier.\n",
    "# print the classification report.\n",
    "# =====================================\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60ccc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
