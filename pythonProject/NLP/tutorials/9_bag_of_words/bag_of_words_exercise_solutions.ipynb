{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcc6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== EXERCISES =============\n",
    "# In this Exercise, you are going to classify whether a given movie review is positive or negative.\n",
    "# you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "# Sklearn CountVectorizer has the inbuilt implementations for Bag of Words.\n",
    "# ===================================\n",
    "\n",
    "\n",
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d9adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I first saw Jake Gyllenhaal in Jarhead (2005) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I enjoyed the movie and the story immensely! I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had a hard time sitting through this. Every ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's hard to imagine that anyone could find th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one military drama I like a lot! Tom B...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive\n",
       "1  I enjoyed the movie and the story immensely! I...  positive\n",
       "2  I had a hard time sitting through this. Every ...  negative\n",
       "3  It's hard to imagine that anyone could find th...  negative\n",
       "4  This is one military drama I like a lot! Tom B...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About Data: IMDB Dataset\n",
    "\n",
    "# Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "# - This data consists of two columns. - review - sentiment\n",
    "# - Reviews are the statements given by users after watching the movie.\n",
    "# - sentiment feature tells whether the given review is positive or negative.\n",
    "\n",
    "# ===============================================\n",
    "\n",
    "\n",
    "#1. read the data provided in the same directory with name 'movies_sentiment_data.csv' and store it in df variable\n",
    "df = pd.read_csv(\"movies_sentiment_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#2. print the shape of the data\n",
    "print(df.shape)\n",
    "\n",
    "#3. print top 5 datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b38be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column \"Category\" which represent 1 if the sentiment is positive or 0 if it is negative\n",
    "df['Category'] = df['sentiment'].apply(lambda x:1 if x=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc8852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9500\n",
       "0    9500\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of 'Category' and see whether the Target labels are balanced or not.\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bc4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.Category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3a772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1882\n",
      "           1       0.85      0.83      0.84      1918\n",
      "\n",
      "    accuracy                           0.84      3800\n",
      "   macro avg       0.84      0.84      0.84      3800\n",
      "weighted avg       0.84      0.84      0.84      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise-1\n",
    "\n",
    "# using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative.\n",
    "# Note:\n",
    "\n",
    "# use CountVectorizer for pre-processing the text.\n",
    "\n",
    "# use Random Forest as the classifier with estimators as 50 and criterion as entropy.\n",
    "\n",
    "# print the classification report.\n",
    "\n",
    "# References:\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "# =====================================================\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), #initializing the vectorizer using the RandomForest classifier\n",
    "    ('random_forest', (RandomForestClassifier(n_estimators=50, criterion='entropy')))\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# As you can see above, for both the classes (positive and negative sentiment) we got more than 80% precision, \n",
    "# recall and f1- score. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4924d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      1882\n",
      "           1       0.64      0.66      0.65      1918\n",
      "\n",
      "    accuracy                           0.64      3800\n",
      "   macro avg       0.64      0.64      0.64      3800\n",
      "weighted avg       0.64      0.64      0.64      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise-2\n",
    "\n",
    "# using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "# Note:\n",
    "\n",
    "# use CountVectorizer for pre-processing the text.\n",
    "# use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean'.\n",
    "# print the classification report.\n",
    "# References:\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "# =============================================\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), #using the KNN classifier with 10 neighbors \n",
    "    ('KNN', (KNeighborsClassifier(n_neighbors=10, metric='euclidean')))\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Hmmm..here the performance of various metrics (precision, recall etc.) seem to be lower (~60 %). \n",
    "# Let's try one more classifier and then discuss why performance is varying so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ec9e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1882\n",
      "           1       0.87      0.82      0.85      1918\n",
      "\n",
      "    accuracy                           0.85      3800\n",
      "   macro avg       0.85      0.85      0.85      3800\n",
      "weighted avg       0.85      0.85      0.85      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise-3\n",
    "\n",
    "# using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "# Note:\n",
    "\n",
    "# use CountVectorizer for pre-processing the text.\n",
    "# use Multinomial Naive Bayes as the classifier.\n",
    "# print the classification report.\n",
    "# References:\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "# ====================================\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('Multi NB', MultinomialNB()) #using the Multinomial Naive Bayes classifier \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ========================================\n",
    "# That's great! MultinomialNB model for both the classes (positive and negative sentiment) we got more than 80% precision, \n",
    "# recall and f1- score and performed equally good with Random Forest. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7517486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
