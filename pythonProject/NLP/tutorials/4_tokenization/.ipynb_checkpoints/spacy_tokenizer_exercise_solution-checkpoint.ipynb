{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa5164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff2d7313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# (1) Think stats is a free book to study statistics \n",
    "# (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n",
    "\n",
    "# This book has references to many websites from where you can download free datasets. You are an NLP engineer working for some\n",
    "# company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from \n",
    "# this book and you want to grab all urls from this paragraph using spacy\n",
    "\n",
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "# Hint: token has an attribute that can be used to detect a url\n",
    "\n",
    "# TODO: Write code here\n",
    "\n",
    "# ============ DRAFT =============\n",
    "# doc = nlp(text)\n",
    "# # doc\n",
    "# urls = []\n",
    "# for token in doc:\n",
    "#     # check if it is a valid url\n",
    "#     if token.like_url:\n",
    "#         urls.append(token.text)\n",
    "# urls\n",
    "\n",
    "# ============ OFFICIAL ============\n",
    "doc = nlp(text)\n",
    "data_websites = [token.text for token in doc if token.like_url]\n",
    "data_websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a87640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "# (2) Extract all money transaction from below sentence along with currency. Output should be,\n",
    "# two $\n",
    "# 500 €\n",
    "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol\n",
    "\n",
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "# TODO: Write code here\n",
    "\n",
    "# ========== OFFICIAL ==========\n",
    "doc = nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb2a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
